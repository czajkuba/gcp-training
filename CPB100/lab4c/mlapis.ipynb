{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Machine Learning APIs </h1>\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chown command to change the ownership of repository to user\n",
    "!sudo chown -R jupyter:jupyter /home/jupyter/gcp-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIKEY=\"YOUR_API_KEY\"  # Replace with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: Make sure you generate an API Key and replace the value above. The sample key will not work.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Translate API </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Translate API\n",
    "from googleapiclient.discovery import build\n",
    "service = build('translate', 'v2', developerKey=APIKEY)\n",
    "\n",
    "# Use the service\n",
    "inputs = ['is it really this easy?', 'amazing technology', 'wow']\n",
    "outputs = service.translations().list(source='en', target='fr', q=inputs).execute()\n",
    "\n",
    "# Print outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print(\"{0} -> {1}\".format(input, output['translatedText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: przetestować translacje pomiędzy kilkoma językami poprzez podmiane parametrów w metodzie wywołaniu API \n",
    "# (np: pl -> de, en -> es, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Invoke Vision API </h2>\n",
    "\n",
    "The Vision API can work off an image in Cloud Storage or embedded directly into a POST message. I'll use Cloud Storage and do OCR on this image: <img src=\"https://storage.googleapis.com/cloud-training-demos/vision/sign2.jpg\" width=\"200\" />.  That photograph is from http://www.publicdomainpictures.net/view-image.php?image=15842\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Vision API\n",
    "import base64\n",
    "import json\n",
    "IMAGE=\"gs://cloud-training-demos/vision/sign2.jpg\"\n",
    "vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "                    'source': {\n",
    "                        'gcs_image_uri': IMAGE\n",
    "                    }\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': 'TEXT_DETECTION',\n",
    "                    'maxResults': 3,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "\n",
    "# Output the `responses`\n",
    "# print(json.dumps(responses, indent=4))\n",
    "print(responses['responses'][0]['textAnnotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreigntext = responses['responses'][0]['textAnnotations'][0]['description']\n",
    "foreignlang = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "\n",
    "# Let's output the `foreignlang` and `foreigntext`\n",
    "print(foreignlang, foreigntext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Translate sign </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=[foreigntext]\n",
    "outputs = service.translations().list(source=foreignlang, target='en', q=inputs).execute()\n",
    "\n",
    "# Print the outputs\n",
    "for input, output in zip(inputs, outputs['translations']):\n",
    "  print(\"{0} -> {1}\".format(input, output['translatedText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Pobrac z internetu obrazek na którym jest osoba z widoczną twarzą\n",
    "# 2. Stworzyć Cloud Storage bucket (Konsola -> Cloud Storage -> Create) (nazwa musi byc globalnie unikalna)\n",
    "# 3. Choose how to control access to objects -> Odznaczyc: Enforce public access prevention on this bucket -> Create\n",
    "# 4. Permissions -> Grant access -> New principals -> allUsers\n",
    "# 5. Role -> Cloud Storage Object Viewer\n",
    "# 6. Wrzucić pobrany obrazek\n",
    "# 7. Wejść w plik, skopiować do schowka gsutil URI i wkleić do zmiennej IMAGE poniżej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = 'YOUR_GS_URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Korzystając z powyzszego przykladu wywolania API Vision AI oraz dokumentacji API:\n",
    "# https://cloud.google.com/vision/docs/reference/rest/v1/Feature\n",
    "# napisać skrypt który będzie wykrywał twarze na pobranym obrazku\n",
    "# 9. Rozparsować odpowiedź API tak aby otrzymać odpowiedź czy osoba na zdjeciu jest usmiechnieta wedlug API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = vservice.images().annotate(body={\n",
    "    #...\n",
    "        })\n",
    "responses = request.execute(num_retries=3)\n",
    "\n",
    "# Printowanie odpowiedzi dla 'faceAnnotations'\n",
    "# print(json.dumps(responses['responses'][0]['faceAnnotations'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Sentiment analysis with Language API </h2>\n",
    "\n",
    "Let's evaluate the sentiment of some famous quotes using Google Cloud Natural Language API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the sentiment with Google Cloud Natural Language API\n",
    "lservice = build('language', 'v1beta1', developerKey=APIKEY)\n",
    "quotes = [\n",
    "  'To succeed, you must have tremendous perseverance, tremendous will.',\n",
    "  'It’s not that I’m so smart, it’s just that I stay with problems longer.',\n",
    "  'Love is quivering happiness.',\n",
    "  'Love is of all passions the strongest, for it attacks simultaneously the head, the heart, and the senses.',\n",
    "  'What difference does it make to the dead, the orphans and the homeless, whether the mad destruction is wrought under the name of totalitarianism or in the holy name of liberty or democracy?',\n",
    "  'When someone you love dies, and you’re not expecting it, you don’t lose her all at once; you lose her in pieces over a long time — the way the mail stops coming, and her scent fades from the pillows and even from the clothes in her closet and drawers. '\n",
    "]\n",
    "for text in quotes:\n",
    "# The `documents.analyzeSentiment` method analyzes the sentiment of the provided text.\n",
    "  response = lservice.documents().analyzeSentiment(\n",
    "    body={\n",
    "      'document': {\n",
    "         'type': 'PLAIN_TEXT',\n",
    "         'content': text\n",
    "      }\n",
    "    }).execute()\n",
    "  polarity = response['documentSentiment']['polarity']\n",
    "  magnitude = response['documentSentiment']['magnitude']\n",
    "\n",
    "# Lets output the value of each `polarity`, `magnitude` and `quote`\n",
    "  print('POLARITY=%s MAGNITUDE=%s for %s' % (polarity, magnitude, quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: napisac skrypt ktory znajdzie i przeanalizuje encje w ponizszym tekscie:\n",
    "text = 'President Trump will speak from the White House, located at 1600 Pennsylvania Ave NW, Washington, DC, on October 7.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: Uzyj metody `documents.analyzeEntities`\n",
    "# https://cloud.google.com/natural-language/docs/reference/rest/v1beta2/Entity\n",
    "response = ...\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: wyprintowac nazwe encji, typ, waznosc (salience) oraz znalezione przez api metadane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in response['entities']:\n",
    "    print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Speech API </h2>\n",
    "\n",
    "The Speech API can work on streaming data, audio content encoded and embedded directly into the POST message, or on a file on Cloud Storage. Here I'll pass in this <a href=\"https://storage.googleapis.com/cloud-training-demos/vision/audio.raw\">audio file</a> in Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Speech API by passing audio file as an argument\n",
    "sservice = build('speech', 'v1', developerKey=APIKEY)\n",
    "# The `speech.recognize` method performs synchronous speech recognition.\n",
    "# It receive results after all audio has been sent and processed.\n",
    "response = sservice.speech().recognize(\n",
    "    body={\n",
    "        'config': {\n",
    "            'languageCode' : 'en-US',\n",
    "            'encoding': 'LINEAR16',\n",
    "            'sampleRateHertz': 16000\n",
    "        },\n",
    "        'audio': {\n",
    "            'uri': 'gs://cloud-training-demos/vision/audio.raw'\n",
    "            }\n",
    "        }).execute()\n",
    "\n",
    "# Let's output the value of `response`\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response['results'][0]['alternatives'][0]['transcript'])\n",
    "\n",
    "# Let's output the value of `'Confidence`\n",
    "print('Confidence=%f' % response['results'][0]['alternatives'][0]['confidence'])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
